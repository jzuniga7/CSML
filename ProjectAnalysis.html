<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ul.lst-kix_col5xqklxhdb-8{list-style-type:none}ul.lst-kix_col5xqklxhdb-6{list-style-type:none}ul.lst-kix_col5xqklxhdb-7{list-style-type:none}ul.lst-kix_col5xqklxhdb-4{list-style-type:none}ul.lst-kix_col5xqklxhdb-5{list-style-type:none}.lst-kix_efmdkksqyvf4-8>li:before{content:"\0025a0  "}.lst-kix_col5xqklxhdb-0>li:before{content:"\0025cf  "}.lst-kix_efmdkksqyvf4-6>li:before{content:"\0025cf  "}.lst-kix_efmdkksqyvf4-7>li:before{content:"\0025cb  "}.lst-kix_efmdkksqyvf4-0>li:before{content:"\0025cf  "}.lst-kix_efmdkksqyvf4-1>li:before{content:"\0025cb  "}ul.lst-kix_efmdkksqyvf4-8{list-style-type:none}.lst-kix_col5xqklxhdb-6>li:before{content:"\0025cf  "}.lst-kix_col5xqklxhdb-8>li:before{content:"\0025a0  "}.lst-kix_efmdkksqyvf4-2>li:before{content:"\0025a0  "}.lst-kix_col5xqklxhdb-7>li:before{content:"\0025cb  "}ul.lst-kix_efmdkksqyvf4-3{list-style-type:none}ul.lst-kix_efmdkksqyvf4-2{list-style-type:none}.lst-kix_efmdkksqyvf4-4>li:before{content:"\0025cb  "}.lst-kix_efmdkksqyvf4-5>li:before{content:"\0025a0  "}ul.lst-kix_efmdkksqyvf4-1{list-style-type:none}ul.lst-kix_efmdkksqyvf4-0{list-style-type:none}.lst-kix_col5xqklxhdb-2>li:before{content:"\0025a0  "}ul.lst-kix_efmdkksqyvf4-7{list-style-type:none}.lst-kix_efmdkksqyvf4-3>li:before{content:"\0025cf  "}ul.lst-kix_efmdkksqyvf4-6{list-style-type:none}ul.lst-kix_efmdkksqyvf4-5{list-style-type:none}ul.lst-kix_efmdkksqyvf4-4{list-style-type:none}.lst-kix_col5xqklxhdb-1>li:before{content:"\0025cb  "}ul.lst-kix_col5xqklxhdb-2{list-style-type:none}ul.lst-kix_col5xqklxhdb-3{list-style-type:none}ul.lst-kix_col5xqklxhdb-0{list-style-type:none}ul.lst-kix_col5xqklxhdb-1{list-style-type:none}.lst-kix_col5xqklxhdb-3>li:before{content:"\0025cf  "}.lst-kix_col5xqklxhdb-4>li:before{content:"\0025cb  "}.lst-kix_col5xqklxhdb-5>li:before{content:"\0025a0  "}ol{margin:0;padding:0}.c5{background-color:#ffffff;font-style:italic;color:#10407f;font-weight:bold}.c0{orphans:2;widows:2;direction:ltr}.c14{background-color:#ffffff;font-size:10.5pt;color:#333333}.c11{background-color:#ffffff;color:#1155cc;text-decoration:underline}.c2{background-color:#ffffff;font-size:10pt;color:#333333}.c16{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{color:inherit;text-decoration:inherit}.c13{background-color:#ffffff;color:#453060}.c15{background-color:#ffffff;color:#003399}.c8{padding:0;margin:0}.c3{font-size:10pt}.c12{font-style:italic}.c6{margin-left:36pt}.c1{font-size:8pt}.c4{height:11pt}.c7{page-break-after:avoid}.c10{padding-left:0pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c16"><p class="c0 c7 title"><a name="h.nh7yv539hq46"></a><span>Practical Machine Learning Project</span></p><p class="c0"><span class="c14">Jay Zuniga</span></p><p class="c0 c4"><span class="c14"></span></p><h3 class="c0 c7"><a name="h.868y6h1wjkeo"></a><span>Purpose</span></h3><p class="c0"><span class="c2">This is the course project for </span><span class="c3 c11"><a class="c9" href="https://www.google.com/url?q=https://class.coursera.org/predmachlearn-034&amp;sa=D&amp;usg=AFQjCNFpFYmp8ltdYSWwPA-FTPVON_UYhA">https://class.coursera.org/predmachlearn-034</a></span><span class="c2">.</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">The goal of the project is to predict the manner in which participants performed a Unilateral Dumbbell Biceps curl in the Weight Lifting Exercise Data Set. Here the participants could perform the exercise in one of five ways:</span></p><p class="c0 c4"><span class="c2"></span></p><ul class="c8 lst-kix_efmdkksqyvf4-0 start"><li class="c0 c6 c10"><span class="c2">Class A: According to specifications</span></li><li class="c0 c6 c10"><span class="c2">Class B: Throwing elbows to the front</span></li><li class="c0 c6 c10"><span class="c2">Class C: Lifting the dumbbell only halfway</span></li><li class="c0 c6 c10"><span class="c2">Class D: Lowering the dumbbell only halfway</span></li><li class="c0 c6 c10"><span class="c2">Class E: Throwing the hips to the front</span></li></ul><p class="c0 c4"><span class="c2"></span></p><h3 class="c0 c7"><a name="h.t8cw2ae6hp92"></a><span>Credits</span></h3><p class="c0"><span class="c2">This project is the dependent on the literature and data set provided by:</span></p><p class="c0"><span class="c3 c12 c13"><a class="c9" href="https://www.google.com/url?q=http://groupware.les.inf.puc-rio.br/collaborator.jsf?p1%3Develloso&amp;sa=D&amp;usg=AFQjCNHGo2Pqp8sMBpzu-SCCCFrJm_v9Ag">Velloso, E.</a></span><span class="c2 c12">; Bulling, A.; Gellersen, H.; </span><span class="c13 c3 c12"><a class="c9" href="https://www.google.com/url?q=http://groupware.les.inf.puc-rio.br/collaborator.jsf?p1%3Dugulino&amp;sa=D&amp;usg=AFQjCNF0wA_5U9Z-GYwR79j053Pc8FqSrA">Ugulino, W.</a></span><span class="c2 c12">; </span><span class="c13 c3 c12"><a class="c9" href="https://www.google.com/url?q=http://groupware.les.inf.puc-rio.br/collaborator.jsf?p1%3Dhugo&amp;sa=D&amp;usg=AFQjCNFptY4zq6enV5t3Fd-XxoamTLeaZg">Fuks, H.</a></span><span class="c2 c12">&nbsp;</span><span class="c3 c5"><a class="c9" href="https://www.google.com/url?q=http://groupware.les.inf.puc-rio.br/work.jsf?p1%3D11201&amp;sa=D&amp;usg=AFQjCNEIyRlMP_ikQF8hASgFQLV9fXjLnQ">Qualitative Activity Recognition of Weight Lifting Exercises</a></span><span class="c2 c12">. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human &#39;13) . Stuttgart, Germany: ACM SIGCHI, 2013.</span></p><p class="c0"><span class="c2">Read more: </span><span class="c3 c15"><a class="c9" href="https://www.google.com/url?q=http://groupware.les.inf.puc-rio.br/har%23ixzz3s95vevFT&amp;sa=D&amp;usg=AFQjCNHcAommyyax2JbZk-UF5Y90PJpNgw">http://groupware.les.inf.puc-rio.br/har#ixzz3s95vevFT</a></span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">To do this we follow the methodology as laid out in Week 1 of the course.</span></p><p class="c0"><span class="c2">Full code is available at: </span><span class="c11 c3"><a class="c9" href="https://www.google.com/url?q=https://github.com/jzuniga7/CSML/blob/master/RfPrediction.md&amp;sa=D&amp;usg=AFQjCNF4ppbRS3jYlPikmhQWeDxMgwJUNg">https://github.com/jzuniga7/CSML/blob/master/RfPrediction.md</a></span></p><p class="c0 c4"><span class="c2"></span></p><h3 class="c0 c7"><a name="h.j6qblfu65513"></a><span>Split data into training, testing and validation</span></h3><p class="c0"><span class="c3">We create the training and test sets from the data provided in the WLE data set. We further split the training set into two (70% and 30% respectively) so that we can cross validate.</span></p><p class="c0 c4"><span></span></p><p class="c0"><span class="c2"># load training set</span></p><p class="c0"><span class="c2">training &lt;- read.csv(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;)</span></p><p class="c0"><span class="c2"># load testing set</span></p><p class="c0"><span class="c2">testing &lt;- read.csv(&quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;)</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2"># Partition training set to allow cross validation</span></p><p class="c0"><span class="c2">inTrain &lt;- createDataPartition(training$classe, p=0.7, list=FALSE)</span></p><p class="c0"><span class="c2">training1 &lt;- training[inTrain,]</span></p><p class="c0"><span class="c2">training2 &lt;- training[-inTrain,]</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0 c4"><span class="c2"></span></p><h3 class="c0 c7"><a name="h.x07db4iqr8mu"></a><span>In Training, pick features</span></h3><p class="c0"><span class="c2">By looking at the data from:</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">summary(training)</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">We can split the features in the data set into four groups.</span></p><p class="c0 c4"><span class="c2"></span></p><ul class="c8 lst-kix_col5xqklxhdb-0 start"><li class="c0 c6 c10"><span class="c2">Group 1: Features that are information about the data set and not good for prediction (e.g. X, user_name)</span></li><li class="c0 c6 c10"><span class="c2">Group 2: Features that have mostly blank values (eg. kurtosis_roll_belt, skewness_roll_belt, amplitude_yaw_dumbbell, etc.)</span></li><li class="c0 c6 c10"><span class="c2">Group 3: Features that are mostly NAs (e.g. amplitude_roll_belt, min_roll_arm, amplitude_roll_dumbbell, etc.)</span></li><li class="c0 c6 c10"><span class="c2">Group 4: Features that have good coverage of values and would be good predictors</span></li></ul><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">Groups 1-3 are not good predictors and we therefore weed them out from the data set, leaving only Group 4 and classe.</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">predictors &lt;- c(&quot;classe&quot;, &quot;roll_belt&quot;,&quot;pitch_belt&quot;, &quot;yaw_belt&quot;,&quot;total_accel_belt&quot;, &quot;gyros_belt_x&quot;, </span></p><p class="c0 c6"><span class="c2">&quot;gyros_belt_y&quot;, &quot;gyros_belt_z&quot;, &quot;accel_belt_x&quot;, &quot;accel_belt_y&quot;, &quot;accel_belt_z&quot;, &quot;magnet_belt_x&quot;, &quot;magnet_belt_y&quot;, &quot;magnet_belt_z&quot;, &quot;roll_arm&quot;,&quot;pitch_arm&quot;, &quot;yaw_arm&quot;, &quot;total_accel_arm&quot;, &quot;gyros_arm_x&quot;, &quot;gyros_arm_y&quot;, &quot;gyros_arm_z&quot;,&quot;accel_arm_x&quot;, &quot;accel_arm_y&quot;, &quot;accel_arm_z&quot;, &quot;magnet_arm_x&quot;, &quot;magnet_arm_y&quot;, &quot;magnet_arm_z&quot;, &quot;roll_dumbbell&quot;, &quot;pitch_dumbbell&quot;, &quot;yaw_dumbbell&quot;, &quot;gyros_dumbbell_x&quot;, &quot;gyros_dumbbell_y&quot;, &quot;gyros_dumbbell_z&quot;,&quot;accel_dumbbell_x&quot;, &quot;accel_dumbbell_y&quot;, &quot;accel_dumbbell_z&quot;, &quot;magnet_dumbbell_x&quot;, &quot;magnet_dumbbell_y&quot;, &quot;magnet_dumbbell_z&quot;, &quot;roll_forearm&quot;, &quot;pitch_forearm&quot;, &quot;yaw_forearm&quot;, &quot;total_accel_forearm&quot;, &quot;total_accel_dumbbell&quot;,</span></p><p class="c0 c6"><span class="c2">&quot;gyros_forearm_x&quot;, &quot;gyros_forearm_y&quot;, &quot;gyros_forearm_z&quot;, &quot;accel_forearm_x&quot;, &quot;accel_forearm_y&quot;, &quot;accel_forearm_z&quot;, &quot;magnet_forearm_x&quot;, &quot;magnet_forearm_y&quot;, &quot;magnet_forearm_z&quot;)</span></p><p class="c0 c4"><span class="c2"></span></p><p class="c0"><span class="c2">training1 &lt;- training1[,predictors]</span></p><p class="c0"><span class="c2">training2 &lt;- training2[,predictors]</span></p><h3 class="c0 c7"><a name="h.mdq3glb47nqw"></a><span>In training, pick prediction function</span></h3><p class="c0 c4"><span></span></p><p class="c0"><span class="c3">We can now train the model using the random forest method as instructed and then use it to predict the training2 data to verify it is working well.</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">modFit &lt;- randomForest(factor(classe)~., data=training1, importance=TRUE)</span></p><p class="c0"><span class="c3">modPredict &lt;- predict(modFit, newdata=training2)</span></p><p class="c0"><span class="c3">confusionMatrix(modPredict, training2$classe)</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">Confusion Matrix and Statistics</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Reference</span></p><p class="c0"><span class="c3">Prediction &nbsp; &nbsp;A &nbsp; &nbsp;B &nbsp; &nbsp;C &nbsp; &nbsp;D &nbsp; &nbsp;E</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;A 1674 &nbsp; &nbsp;1 &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; &nbsp;0</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;B &nbsp; &nbsp;0 1132 &nbsp; &nbsp;3 &nbsp; &nbsp;0 &nbsp; &nbsp;0</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;C &nbsp; &nbsp;0 &nbsp; &nbsp;6 1021 &nbsp; &nbsp;2 &nbsp; &nbsp;0</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;D &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; &nbsp;2 &nbsp;962 &nbsp; &nbsp;2</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;E &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; &nbsp;0 &nbsp; &nbsp;0 1080</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">Overall Statistics</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Accuracy : 0.9973 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;95% CI : (0.9956, 0.9984)</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; No Information Rate : 0.2845 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c0"><span class="c3">&nbsp; &nbsp; P-Value [Acc &gt; NIR] : &lt; 2.2e-16 &nbsp; &nbsp; &nbsp; </span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Kappa : 0.9966 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c0"><span class="c3">&nbsp;Mcnemar&#39;s Test P-Value : NA &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">Statistics by Class:</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Class: A Class: B Class: C Class: D Class: E</span></p><p class="c0"><span class="c3">Sensitivity &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;1.0000 &nbsp; 0.9939 &nbsp; 0.9951 &nbsp; 0.9979 &nbsp; 0.9982</span></p><p class="c0"><span class="c3">Specificity &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.9998 &nbsp; 0.9994 &nbsp; 0.9984 &nbsp; 0.9992 &nbsp; 1.0000</span></p><p class="c0"><span class="c3">Pos Pred Value &nbsp; &nbsp; &nbsp; &nbsp; 0.9994 &nbsp; 0.9974 &nbsp; 0.9922 &nbsp; 0.9959 &nbsp; 1.0000</span></p><p class="c0"><span class="c3">Neg Pred Value &nbsp; &nbsp; &nbsp; &nbsp; 1.0000 &nbsp; 0.9985 &nbsp; 0.9990 &nbsp; 0.9996 &nbsp; 0.9996</span></p><p class="c0"><span class="c3">Prevalence &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.2845 &nbsp; 0.1935 &nbsp; 0.1743 &nbsp; 0.1638 &nbsp; 0.1839</span></p><p class="c0"><span class="c3">Detection Rate &nbsp; &nbsp; &nbsp; &nbsp; 0.2845 &nbsp; 0.1924 &nbsp; 0.1735 &nbsp; 0.1635 &nbsp; 0.1835</span></p><p class="c0"><span class="c3">Detection Prevalence &nbsp; 0.2846 &nbsp; 0.1929 &nbsp; 0.1749 &nbsp; 0.1641 &nbsp; 0.1835</span></p><p class="c0"><span class="c3">Balanced Accuracy &nbsp; &nbsp; &nbsp;0.9999 &nbsp; 0.9966 &nbsp; 0.9967 &nbsp; 0.9986 &nbsp; 0.9991</span></p><p class="c0 c4"><span class="c3"></span></p><h3 class="c0 c7"><a name="h.enm0153hgtgi"></a><span>Predicting the error</span></h3><p class="c0"><span class="c1">Based on </span><span class="c3">prediction on the training2 data set, the accuracy was very high with misclassifications for A:1/1674, B:3/1132, C:6/1021, D:2/962, E:0/1080. With an accuracy of 99.73%, the out of sample error is .27%.</span></p><h3 class="c0 c7"><a name="h.20p6w53t9n0u"></a><span>Predict the testing data set</span></h3><p class="c0"><span class="c3">With the model verified, we can now use the model to predict 20 cases from the testing data set.</span></p><p class="c0 c4"><span class="c3"></span></p><p class="c0"><span class="c3">modPredict2 &lt;- predict(modFit, newdata=testing)</span></p><p class="c0"><span class="c3">&gt; modPredict2</span></p><p class="c0"><span class="c3">&nbsp;1 &nbsp;2 &nbsp;3 &nbsp;4 &nbsp;5 &nbsp;6 &nbsp;7 &nbsp;8 &nbsp;9 10 11 12 13 14 15 16 17 18 19 20 </span></p><p class="c0"><span class="c3">&nbsp;B &nbsp;A &nbsp;B &nbsp;A &nbsp;A &nbsp;E &nbsp;D &nbsp;B &nbsp;A &nbsp;A &nbsp;B &nbsp;C &nbsp;B &nbsp;A &nbsp;E &nbsp;E &nbsp;A &nbsp;B &nbsp;B &nbsp;B </span></p><p class="c0"><span class="c3">Levels: A B C D E</span></p><p class="c0 c4"><span class="c14"></span></p></body></html>
